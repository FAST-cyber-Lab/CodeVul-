{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f53b6717-477d-4565-8e83-5373adb72456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate, Layer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "def remo(code):\n",
    "    # Check if input is a string\n",
    "    if not isinstance(code, str):\n",
    "        return code\n",
    "        \n",
    "    code = re.sub(r'/\\.?\\*/', '', code, flags=re.DOTALL)\n",
    "    code = re.sub(r'//.*?$', '', code, flags=re.MULTILINE)\n",
    "    code = re.sub(r'^\\s*[\\n\\r]', '', code, flags=re.MULTILINE)\n",
    "    return code.strip()\n",
    "\n",
    "# Apply the function to the 'func' column (or whatever your code column is named)\n",
    "\n",
    "train = pd.read_csv(\"/Users/user01/fahim/icsme/train_label_dataset.csv\")\n",
    "test = pd.read_csv(\"/Users/user01/fahim/icsme/test_label_dataset.csv\")\n",
    "train['functionSource'] = train['functionSource'].apply(remo)\n",
    "test['functionSource'] = test['functionSource'].apply(remo)\n",
    "\n",
    "train = train[['functionSource', 'numeric']]\n",
    "test = test[['functionSource', 'numeric']]\n",
    "\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "081fbecc-cb7b-4664-9e48-6d8dfa0d1c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionSource</th>\n",
       "      <th>label</th>\n",
       "      <th>numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ng_mix_init(struct ng_devstate *dev, char *dev...</td>\n",
       "      <td>CWE-other</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>execdotcmd(const char *cmd, char *defcmd, cons...</td>\n",
       "      <td>CWE-476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setBlockIndent(QTextBlock block, int indent)\\n...</td>\n",
       "      <td>CWE-119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efi_snp_notify ( struct net_device *netdev ) {...</td>\n",
       "      <td>CWE-119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dir_ctrl(X509_LOOKUP *ctx, int cmd, const char...</td>\n",
       "      <td>CWE-other</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      functionSource      label  numeric\n",
       "0  ng_mix_init(struct ng_devstate *dev, char *dev...  CWE-other        4\n",
       "1  execdotcmd(const char *cmd, char *defcmd, cons...    CWE-476        3\n",
       "2  setBlockIndent(QTextBlock block, int indent)\\n...    CWE-119        0\n",
       "3  efi_snp_notify ( struct net_device *netdev ) {...    CWE-119        0\n",
       "4  dir_ctrl(X509_LOOKUP *ctx, int cmd, const char...  CWE-other        4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80b433b5-809f-4255-9f03-8ba4a099cafd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "434faccb-517a-402f-b2e7-e2194906de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user01\\.conda\\envs\\myenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 1s/step - accuracy: 0.1993 - loss: 1.8955\n",
      "Epoch 2/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 1s/step - accuracy: 0.1945 - loss: 1.6099\n",
      "Epoch 3/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 1s/step - accuracy: 0.2054 - loss: 1.6096\n",
      "Epoch 4/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 1s/step - accuracy: 0.1922 - loss: 1.6095\n",
      "Epoch 5/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 1s/step - accuracy: 0.1982 - loss: 1.6095\n",
      "Epoch 6/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 1s/step - accuracy: 0.2024 - loss: 1.6094\n",
      "Epoch 7/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 1s/step - accuracy: 0.2018 - loss: 1.6095\n",
      "Epoch 8/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 1s/step - accuracy: 0.1974 - loss: 1.6095\n",
      "Epoch 9/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 889ms/step - accuracy: 0.2016 - loss: 1.6095\n",
      "Epoch 10/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 1s/step - accuracy: 0.2037 - loss: 1.6095\n",
      "Epoch 11/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 1s/step - accuracy: 0.2019 - loss: 1.6094\n",
      "Epoch 12/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 1s/step - accuracy: 0.2053 - loss: 1.6094\n",
      "Epoch 13/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 994ms/step - accuracy: 0.2004 - loss: 1.6094\n",
      "Epoch 14/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 970ms/step - accuracy: 0.1979 - loss: 1.6094\n",
      "Epoch 15/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 1s/step - accuracy: 0.2022 - loss: 1.6094\n",
      "Epoch 16/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 975ms/step - accuracy: 0.1978 - loss: 1.6095\n",
      "Epoch 17/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 971ms/step - accuracy: 0.1983 - loss: 1.6095\n",
      "Epoch 18/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 981ms/step - accuracy: 0.2002 - loss: 1.6094\n",
      "Epoch 19/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 891ms/step - accuracy: 0.2003 - loss: 1.6095\n",
      "Epoch 20/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 847ms/step - accuracy: 0.2046 - loss: 1.6094\n",
      "Epoch 21/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 978ms/step - accuracy: 0.1966 - loss: 1.6095\n",
      "Epoch 22/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 984ms/step - accuracy: 0.2011 - loss: 1.6095\n",
      "Epoch 23/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 981ms/step - accuracy: 0.2027 - loss: 1.6095\n",
      "Epoch 24/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 968ms/step - accuracy: 0.1990 - loss: 1.6095\n",
      "Epoch 25/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 966ms/step - accuracy: 0.2061 - loss: 1.6095\n",
      "Epoch 26/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 979ms/step - accuracy: 0.1985 - loss: 1.6094\n",
      "Epoch 27/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 978ms/step - accuracy: 0.1965 - loss: 1.6094\n",
      "Epoch 28/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 986ms/step - accuracy: 0.2004 - loss: 1.6095\n",
      "Epoch 29/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 981ms/step - accuracy: 0.2041 - loss: 1.6094\n",
      "Epoch 30/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 983ms/step - accuracy: 0.2011 - loss: 1.6094\n",
      "Epoch 31/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 988ms/step - accuracy: 0.2066 - loss: 1.6094\n",
      "Epoch 32/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 993ms/step - accuracy: 0.2061 - loss: 1.6094\n",
      "Epoch 33/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 992ms/step - accuracy: 0.2058 - loss: 1.6094\n",
      "Epoch 34/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 985ms/step - accuracy: 0.2033 - loss: 1.6094\n",
      "Epoch 35/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 992ms/step - accuracy: 0.1981 - loss: 1.6094\n",
      "Epoch 36/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 984ms/step - accuracy: 0.2000 - loss: 1.6095\n",
      "Epoch 37/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 985ms/step - accuracy: 0.2027 - loss: 1.6094\n",
      "Epoch 38/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 979ms/step - accuracy: 0.2018 - loss: 1.6094\n",
      "Epoch 39/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 991ms/step - accuracy: 0.1996 - loss: 1.6094\n",
      "Epoch 40/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 989ms/step - accuracy: 0.2076 - loss: 1.6094\n",
      "Epoch 41/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 994ms/step - accuracy: 0.2004 - loss: 1.6094\n",
      "Epoch 42/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 999ms/step - accuracy: 0.2019 - loss: 1.6094\n",
      "Epoch 43/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 992ms/step - accuracy: 0.2060 - loss: 1.6094\n",
      "Epoch 44/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 990ms/step - accuracy: 0.2024 - loss: 1.6094\n",
      "Epoch 45/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 986ms/step - accuracy: 0.2079 - loss: 1.6094\n",
      "Epoch 46/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 993ms/step - accuracy: 0.2019 - loss: 1.6094\n",
      "Epoch 47/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6363s\u001b[0m 23s/step - accuracy: 0.2056 - loss: 1.6094\n",
      "Epoch 48/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 1s/step - accuracy: 0.2038 - loss: 1.6094\n",
      "Epoch 49/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 1s/step - accuracy: 0.2048 - loss: 1.6094\n",
      "Epoch 50/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 1s/step - accuracy: 0.2025 - loss: 1.6094\n",
      "Epoch 51/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 1s/step - accuracy: 0.2025 - loss: 1.6094\n",
      "Epoch 52/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.1986 - loss: 1.6095\n",
      "Epoch 53/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 1s/step - accuracy: 0.2044 - loss: 1.6094\n",
      "Epoch 54/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.2082 - loss: 1.6094\n",
      "Epoch 55/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 1s/step - accuracy: 0.2043 - loss: 1.6094\n",
      "Epoch 56/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.1988 - loss: 1.6094\n",
      "Epoch 57/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.1983 - loss: 1.6095\n",
      "Epoch 58/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.2030 - loss: 1.6094\n",
      "Epoch 59/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 1s/step - accuracy: 0.2021 - loss: 1.6094\n",
      "Epoch 60/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 1s/step - accuracy: 0.2009 - loss: 1.6094\n",
      "Epoch 1/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 218ms/step - accuracy: 0.1968 - loss: 1.9850\n",
      "Epoch 2/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 229ms/step - accuracy: 0.2031 - loss: 1.6108\n",
      "Epoch 3/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 228ms/step - accuracy: 0.1988 - loss: 1.6100\n",
      "Epoch 4/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 227ms/step - accuracy: 0.2041 - loss: 1.6097\n",
      "Epoch 5/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 228ms/step - accuracy: 0.2035 - loss: 1.6095\n",
      "Epoch 6/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 229ms/step - accuracy: 0.2031 - loss: 1.6095\n",
      "Epoch 7/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 229ms/step - accuracy: 0.1995 - loss: 1.6095\n",
      "Epoch 8/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 237ms/step - accuracy: 0.2001 - loss: 1.6094\n",
      "Epoch 9/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 230ms/step - accuracy: 0.2040 - loss: 1.6095\n",
      "Epoch 10/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 227ms/step - accuracy: 0.2033 - loss: 1.6095\n",
      "Epoch 11/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 228ms/step - accuracy: 0.2006 - loss: 1.6094\n",
      "Epoch 12/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 228ms/step - accuracy: 0.1992 - loss: 1.6095\n",
      "Epoch 13/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 225ms/step - accuracy: 0.1963 - loss: 1.6095\n",
      "Epoch 14/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.1993 - loss: 1.6094\n",
      "Epoch 15/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 225ms/step - accuracy: 0.2072 - loss: 1.6094\n",
      "Epoch 16/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 225ms/step - accuracy: 0.2004 - loss: 1.6094\n",
      "Epoch 17/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 223ms/step - accuracy: 0.2032 - loss: 1.6094\n",
      "Epoch 18/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 225ms/step - accuracy: 0.2037 - loss: 1.6095\n",
      "Epoch 19/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 225ms/step - accuracy: 0.2028 - loss: 1.6094\n",
      "Epoch 20/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 209ms/step - accuracy: 0.2029 - loss: 1.6094\n",
      "Epoch 21/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 220ms/step - accuracy: 0.2025 - loss: 1.6095\n",
      "Epoch 22/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 222ms/step - accuracy: 0.2032 - loss: 1.6095\n",
      "Epoch 23/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 220ms/step - accuracy: 0.2014 - loss: 1.6094\n",
      "Epoch 24/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.2071 - loss: 1.6094\n",
      "Epoch 25/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 223ms/step - accuracy: 0.2017 - loss: 1.6095\n",
      "Epoch 26/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.1982 - loss: 1.6095\n",
      "Epoch 27/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 225ms/step - accuracy: 0.2050 - loss: 1.6094\n",
      "Epoch 28/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 225ms/step - accuracy: 0.2063 - loss: 1.6094\n",
      "Epoch 29/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.1973 - loss: 1.6095\n",
      "Epoch 30/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 221ms/step - accuracy: 0.1974 - loss: 1.6095\n",
      "Epoch 31/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 219ms/step - accuracy: 0.1993 - loss: 1.6094\n",
      "Epoch 32/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 225ms/step - accuracy: 0.1959 - loss: 1.6094\n",
      "Epoch 33/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 225ms/step - accuracy: 0.2063 - loss: 1.6094\n",
      "Epoch 34/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 221ms/step - accuracy: 0.2027 - loss: 1.6094\n",
      "Epoch 35/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 220ms/step - accuracy: 0.2013 - loss: 1.6094\n",
      "Epoch 36/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 222ms/step - accuracy: 0.1989 - loss: 1.6094\n",
      "Epoch 37/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 221ms/step - accuracy: 0.2004 - loss: 1.6095\n",
      "Epoch 38/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 220ms/step - accuracy: 0.2019 - loss: 1.6094\n",
      "Epoch 39/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 222ms/step - accuracy: 0.1939 - loss: 1.6095\n",
      "Epoch 40/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 225ms/step - accuracy: 0.2017 - loss: 1.6094\n",
      "Epoch 41/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.2034 - loss: 1.6094\n",
      "Epoch 42/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 221ms/step - accuracy: 0.2013 - loss: 1.6094\n",
      "Epoch 43/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.2047 - loss: 1.6094\n",
      "Epoch 44/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 228ms/step - accuracy: 0.2069 - loss: 1.6094\n",
      "Epoch 45/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.2093 - loss: 1.6094\n",
      "Epoch 46/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 221ms/step - accuracy: 0.2026 - loss: 1.6094\n",
      "Epoch 47/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 221ms/step - accuracy: 0.2033 - loss: 1.6094\n",
      "Epoch 48/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 221ms/step - accuracy: 0.2011 - loss: 1.6094\n",
      "Epoch 49/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 225ms/step - accuracy: 0.2047 - loss: 1.6094\n",
      "Epoch 50/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 225ms/step - accuracy: 0.2044 - loss: 1.6094\n",
      "Epoch 51/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 222ms/step - accuracy: 0.2017 - loss: 1.6094\n",
      "Epoch 52/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 221ms/step - accuracy: 0.2019 - loss: 1.6094\n",
      "Epoch 53/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 223ms/step - accuracy: 0.2009 - loss: 1.6094\n",
      "Epoch 54/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.2019 - loss: 1.6094\n",
      "Epoch 55/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.2036 - loss: 1.6094\n",
      "Epoch 56/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.2024 - loss: 1.6094\n",
      "Epoch 57/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 223ms/step - accuracy: 0.2038 - loss: 1.6094\n",
      "Epoch 58/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 224ms/step - accuracy: 0.2009 - loss: 1.6094\n",
      "Epoch 59/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 220ms/step - accuracy: 0.2020 - loss: 1.6095\n",
      "Epoch 60/60\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 217ms/step - accuracy: 0.2015 - loss: 1.6094\n",
      "Epoch 1/10\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 1s/step - accuracy: 0.1989 - loss: 1.9060\n",
      "Epoch 2/10\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 1s/step - accuracy: 0.2019 - loss: 1.6137\n",
      "Epoch 3/10\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 1s/step - accuracy: 0.2035 - loss: 1.6103\n",
      "Epoch 4/10\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 1s/step - accuracy: 0.2000 - loss: 1.6110\n",
      "Epoch 5/10\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 1s/step - accuracy: 0.2031 - loss: 1.6102\n",
      "Epoch 6/10\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 1s/step - accuracy: 0.1981 - loss: 1.6109\n",
      "Epoch 7/10\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 1s/step - accuracy: 0.1989 - loss: 1.6108\n",
      "Epoch 8/10\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 1s/step - accuracy: 0.2009 - loss: 1.6109\n",
      "Epoch 9/10\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 1s/step - accuracy: 0.1956 - loss: 1.6111\n",
      "Epoch 10/10\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 1s/step - accuracy: 0.1944 - loss: 1.6105\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 258ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       934\n",
      "           1       0.00      0.00      0.00       860\n",
      "           2       0.00      0.00      0.00       918\n",
      "           3       0.00      0.00      0.00       909\n",
      "           4       0.20      1.00      0.33       879\n",
      "\n",
      "    accuracy                           0.20      4500\n",
      "   macro avg       0.04      0.20      0.07      4500\n",
      "weighted avg       0.04      0.20      0.06      4500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user01\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\user01\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\user01\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate, Layer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_GLOBAL_LOCAL = 60\n",
    "EPOCHS_FUSION = 10\n",
    "DROPOUT_RATE = 0.5\n",
    "\n",
    "GLOBAL_NODES = 300\n",
    "LOCAL_NODES = 200\n",
    "FUSION_NODES = 500\n",
    "VECTOR_DIM = 50\n",
    "MAX_GLOBAL_LENGTH = 300\n",
    "MAX_LOCAL_LENGTH = 100\n",
    "\n",
    "def parse_code_gadgets(source_code):\n",
    "    return [[\"int\", \"main\", \"(\", \")\", \"{\"], [\"return\", \"0\", \";\", \"}\"]]\n",
    "\n",
    "def parse_code_attention(code_gadgets):\n",
    "    return [[\"main\", \"{\"], [\"return\", \"0\"]]\n",
    "\n",
    "class CustomAttention(Layer):\n",
    "    def call(self, inputs):\n",
    "        query, value = inputs, inputs\n",
    "        scores = tf.matmul(query, value, transpose_b=True)\n",
    "        distribution = tf.nn.softmax(scores, axis=-1)\n",
    "        attention_output = tf.matmul(distribution, value)\n",
    "        return attention_output\n",
    "\n",
    "def convert_to_vectors(gadgets, word2vec_model, max_length):\n",
    "    vectors = []\n",
    "    for gadget in gadgets:\n",
    "        gadget_vectors = [\n",
    "            word2vec_model.wv[word] if word in word2vec_model.wv else np.zeros(word2vec_model.vector_size)\n",
    "            for word in gadget\n",
    "        ]\n",
    "        if len(gadget_vectors) < max_length:\n",
    "            gadget_vectors += [np.zeros(word2vec_model.vector_size)] * (max_length - len(gadget_vectors))\n",
    "        else:\n",
    "            gadget_vectors = gadget_vectors[:max_length]\n",
    "        vectors.append(gadget_vectors)\n",
    "    return np.array(vectors)\n",
    "\n",
    "def global_feature_model():\n",
    "    global_input = Input(shape=(MAX_GLOBAL_LENGTH, VECTOR_DIM), name=\"global_input\")\n",
    "    lstm_layer = LSTM(GLOBAL_NODES, activation=\"tanh\", return_sequences=True)(global_input)\n",
    "    attention_layer = CustomAttention()(lstm_layer)\n",
    "    lstm_output = LSTM(GLOBAL_NODES, activation=\"tanh\")(attention_layer)\n",
    "    return Model(global_input, lstm_output, name=\"global_model\")\n",
    "\n",
    "def local_feature_model():\n",
    "    local_input = Input(shape=(MAX_LOCAL_LENGTH, VECTOR_DIM), name=\"local_input\")\n",
    "    lstm_layer = LSTM(LOCAL_NODES, activation=\"tanh\", return_sequences=True)(local_input)\n",
    "    attention_layer = CustomAttention()(lstm_layer)\n",
    "    lstm_output = LSTM(LOCAL_NODES, activation=\"tanh\")(attention_layer)\n",
    "    return Model(local_input, lstm_output, name=\"local_model\")\n",
    "\n",
    "def feature_fusion_model(global_model, local_model):\n",
    "    global_input = global_model.input\n",
    "    local_input = local_model.input\n",
    "    merged_features = Concatenate()([global_model.output, local_model.output])\n",
    "    dense_layer = Dense(FUSION_NODES, activation=\"tanh\")(merged_features)\n",
    "    dropout_layer = Dropout(DROPOUT_RATE)(dense_layer)\n",
    "    output_layer = Dense(5, activation=\"softmax\")(dropout_layer)\n",
    "    return Model([global_input, local_input], output_layer, name=\"fusion_model\")\n",
    "\n",
    "def process_code_samples(df, column_name):\n",
    "    source_code_samples = df[column_name].tolist()\n",
    "    code_gadgets = [parse_code_gadgets(code) for code in source_code_samples]\n",
    "    code_attentions = [parse_code_attention(gadgets) for gadgets in code_gadgets]\n",
    "    corpus = [token for gadgets in code_gadgets for token in gadgets]\n",
    "    word2vec_model = Word2Vec(sentences=corpus, vector_size=VECTOR_DIM, window=5, min_count=1, workers=4)\n",
    "    X_global = np.array([convert_to_vectors(gadgets, word2vec_model, MAX_GLOBAL_LENGTH)[0] for gadgets in code_gadgets])\n",
    "    X_local = np.array([convert_to_vectors(attentions, word2vec_model, MAX_LOCAL_LENGTH)[0] for attentions in code_attentions])\n",
    "    return X_global, X_local, word2vec_model\n",
    "\n",
    "X_train_global, X_train_local, word2vec_model = process_code_samples(train, \"functionSource\")\n",
    "Y_train = train[\"numeric\"].values\n",
    "X_test_global, X_test_local, _ = process_code_samples(test, \"functionSource\")\n",
    "Y_test = test[\"numeric\"].values\n",
    "\n",
    "global_model = global_feature_model()\n",
    "local_model = local_feature_model()\n",
    "\n",
    "global_model.compile(optimizer=RMSprop(LEARNING_RATE), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "global_model.fit(X_train_global, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS_GLOBAL_LOCAL)\n",
    "\n",
    "local_model.compile(optimizer=RMSprop(LEARNING_RATE), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "local_model.fit(X_train_local, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS_GLOBAL_LOCAL)\n",
    "\n",
    "fusion_model = feature_fusion_model(global_model, local_model)\n",
    "fusion_model.compile(optimizer=RMSprop(LEARNING_RATE), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "fusion_model.fit([X_train_global, X_train_local], Y_train, batch_size=BATCH_SIZEfcdvdvv, epochs=EPOCHS_FUSION)\n",
    "\n",
    "Y_pred = fusion_model.predict([X_test_global, X_test_local])\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "print(classification_report(Y_test, Y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90959aa6-9fbc-400e-8eb2-e9e4921d7977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 244ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       934\n",
      "           1       0.00      0.00      0.00       860\n",
      "           2       0.00      0.00      0.00       918\n",
      "           3       0.00      0.00      0.00       909\n",
      "           4       0.20      1.00      0.33       879\n",
      "\n",
      "    accuracy                           0.20      4500\n",
      "   macro avg       0.04      0.20      0.07      4500\n",
      "weighted avg       0.04      0.20      0.06      4500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   0 934]\n",
      " [  0   0   0   0 860]\n",
      " [  0   0   0   0 918]\n",
      " [  0   0   0   0 909]\n",
      " [  0   0   0   0 879]]\n",
      "\n",
      "Accuracy: 0.19533333333333333\n",
      "\n",
      "Precision (Macro): 0.039066666666666666\n",
      "Recall (Macro): 0.2\n",
      "F1 Score (Macro): 0.06536530953708868\n",
      "\n",
      "Precision (Weighted): 0.03815511111111111\n",
      "Recall (Weighted): 0.19533333333333333\n",
      "F1 Score (Weighted): 0.06384011898122327\n",
      "\n",
      "Matthews Correlation Coefficient: 0.0\n",
      "\n",
      "Cohen's Kappa Score: 0.0\n",
      "\n",
      "ROC AUC Score (Macro): 0.5\n",
      "\n",
      "Mean Squared Error (MSE): 6.058888888888889\n",
      "Mean Absolute Error (MAE): 2.0135555555555555\n",
      "\n",
      "Metrics Summary:\n",
      "Accuracy: 0.19533333333333333\n",
      "Precision (Macro): 0.039066666666666666\n",
      "Recall (Macro): 0.2\n",
      "F1 Score (Macro): 0.06536530953708868\n",
      "Precision (Weighted): 0.03815511111111111\n",
      "Recall (Weighted): 0.19533333333333333\n",
      "F1 Score (Weighted): 0.06384011898122327\n",
      "Matthews Correlation Coefficient (MCC): 0.0\n",
      "Cohen's Kappa: 0.0\n",
      "Mean Squared Error (MSE): 6.058888888888889\n",
      "Mean Absolute Error (MAE): 2.0135555555555555\n",
      "ROC AUC Score (Macro): 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user01\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\user01\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\user01\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    cohen_kappa_score,\n",
    "    roc_auc_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "\n",
    "Y_pred = fusion_model.predict([X_test_global, X_test_local])\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, Y_pred_classes))\n",
    "\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred_classes)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred_classes)\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "\n",
    "precision_macro = precision_score(Y_test, Y_pred_classes, average=\"macro\", zero_division=0)\n",
    "recall_macro = recall_score(Y_test, Y_pred_classes, average=\"macro\", zero_division=0)\n",
    "f1_macro = f1_score(Y_test, Y_pred_classes, average=\"macro\", zero_division=0)\n",
    "\n",
    "precision_weighted = precision_score(Y_test, Y_pred_classes, average=\"weighted\", zero_division=0)\n",
    "recall_weighted = recall_score(Y_test, Y_pred_classes, average=\"weighted\", zero_division=0)\n",
    "f1_weighted = f1_score(Y_test, Y_pred_classes, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(f\"\\nPrecision (Macro): {precision_macro}\")\n",
    "print(f\"Recall (Macro): {recall_macro}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro}\")\n",
    "\n",
    "print(f\"\\nPrecision (Weighted): {precision_weighted}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted}\")\n",
    "\n",
    "mcc = matthews_corrcoef(Y_test, Y_pred_classes)\n",
    "print(f\"\\nMatthews Correlation Coefficient: {mcc}\")\n",
    "\n",
    "kappa = cohen_kappa_score(Y_test, Y_pred_classes)\n",
    "print(f\"\\nCohen's Kappa Score: {kappa}\")\n",
    "\n",
    "try:\n",
    "    roc_auc = roc_auc_score(pd.get_dummies(Y_test), Y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "    print(f\"\\nROC AUC Score (Macro): {roc_auc}\")\n",
    "except ValueError:\n",
    "    print(\"\\nROC AUC Score could not be computed due to label imbalance or insufficient classes.\")\n",
    "\n",
    "# Error Metrics\n",
    "mse = mean_squared_error(Y_test, Y_pred_classes)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_classes)\n",
    "\n",
    "print(f\"\\nMean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# All Computed Metrics Summary\n",
    "metrics_summary = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision (Macro)\": precision_macro,\n",
    "    \"Recall (Macro)\": recall_macro,\n",
    "    \"F1 Score (Macro)\": f1_macro,\n",
    "    \"Precision (Weighted)\": precision_weighted,\n",
    "    \"Recall (Weighted)\": recall_weighted,\n",
    "    \"F1 Score (Weighted)\": f1_weighted,\n",
    "    \"Matthews Correlation Coefficient (MCC)\": mcc,\n",
    "    \"Cohen's Kappa\": kappa,\n",
    "    \"Mean Squared Error (MSE)\": mse,\n",
    "    \"Mean Absolute Error (MAE)\": mae,\n",
    "}\n",
    "\n",
    "if \"roc_auc\" in locals():\n",
    "    metrics_summary[\"ROC AUC Score (Macro)\"] = roc_auc\n",
    "\n",
    "print(\"\\nMetrics Summary:\")\n",
    "for metric, value in metrics_summary.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "662fb7e1-dc20-4b04-8525-02b250fac052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0:\n",
      "  TP: 0, FP: 0, FN: 934, TN: 3566\n",
      "  Sensitivity (Recall): 0.0\n",
      "  Specificity: 0.9999999999999719\n",
      "\n",
      "Class 1:\n",
      "  TP: 0, FP: 0, FN: 860, TN: 3640\n",
      "  Sensitivity (Recall): 0.0\n",
      "  Specificity: 0.9999999999999725\n",
      "\n",
      "Class 2:\n",
      "  TP: 0, FP: 0, FN: 918, TN: 3582\n",
      "  Sensitivity (Recall): 0.0\n",
      "  Specificity: 0.999999999999972\n",
      "\n",
      "Class 3:\n",
      "  TP: 0, FP: 0, FN: 909, TN: 3591\n",
      "  Sensitivity (Recall): 0.0\n",
      "  Specificity: 0.9999999999999721\n",
      "\n",
      "Class 4:\n",
      "  TP: 879, FP: 3621, FN: 0, TN: 0\n",
      "  Sensitivity (Recall): 0.9999999999998862\n",
      "  Specificity: 0.0\n",
      "\n",
      "\n",
      "Overall Sensitivity (Recall): 0.19999999999997725\n",
      "Overall Specificity: 0.7999999999999777\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred_classes)\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "# Initialize lists to store per-class metrics\n",
    "TP = np.diag(conf_matrix)  # True Positives for each class\n",
    "FP = np.sum(conf_matrix, axis=0) - TP  # False Positives for each class\n",
    "FN = np.sum(conf_matrix, axis=1) - TP  # False Negatives for each class\n",
    "TN = np.sum(conf_matrix) - (TP + FP + FN)  # True Negatives for each class\n",
    "\n",
    "# Compute sensitivity (recall) and specificity for each class\n",
    "sensitivity_per_class = TP / (TP + FN + 1e-10)  # Avoid division by zero\n",
    "specificity_per_class = TN / (TN + FP + 1e-10)\n",
    "\n",
    "# Compute overall (macro-average) sensitivity and specificity\n",
    "overall_sensitivity = np.mean(sensitivity_per_class)\n",
    "overall_specificity = np.mean(specificity_per_class)\n",
    "\n",
    "# Print per-class metrics\n",
    "for i in range(num_classes):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  TP: {TP[i]}, FP: {FP[i]}, FN: {FN[i]}, TN: {TN[i]}\")\n",
    "    print(f\"  Sensitivity (Recall): {sensitivity_per_class[i]}\")\n",
    "    print(f\"  Specificity: {specificity_per_class[i]}\\n\")\n",
    "\n",
    "# Print overall metrics\n",
    "print(f\"\\nOverall Sensitivity (Recall): {overall_sensitivity}\")\n",
    "print(f\"Overall Specificity: {overall_specificity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15565797-ca6b-48f7-8bd6-2161056702dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv]",
   "language": "python",
   "name": "conda-env-.conda-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
