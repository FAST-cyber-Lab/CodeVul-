{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53b6717-477d-4565-8e83-5373adb72456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate, Layer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80b433b5-809f-4255-9f03-8ba4a099cafd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "434faccb-517a-402f-b2e7-e2194906de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dl/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3084\n",
      "Epoch 2, Loss: 1.1952\n",
      "Epoch 3, Loss: 1.1525\n",
      "Epoch 4, Loss: 1.1247\n",
      "Epoch 5, Loss: 1.1032\n",
      "Epoch 6, Loss: 1.0930\n",
      "Epoch 7, Loss: 1.0764\n",
      "Epoch 8, Loss: 1.0640\n",
      "Epoch 9, Loss: 1.0568\n",
      "Epoch 10, Loss: 1.0465\n",
      "Epoch 11, Loss: 1.0355\n",
      "Epoch 12, Loss: 1.0253\n",
      "Epoch 13, Loss: 1.0212\n",
      "Epoch 14, Loss: 1.0141\n",
      "Epoch 15, Loss: 1.0099\n",
      "Epoch 16, Loss: 1.0005\n",
      "Epoch 17, Loss: 0.9973\n",
      "Epoch 18, Loss: 0.9867\n",
      "Epoch 19, Loss: 0.9850\n",
      "Epoch 20, Loss: 0.9810\n",
      "Performance on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       934\n",
      "           1       0.24      0.35      0.29       860\n",
      "           2       0.00      0.00      0.00       918\n",
      "           3       0.29      0.12      0.17       909\n",
      "           4       0.18      0.58      0.27       879\n",
      "\n",
      "    accuracy                           0.20      4500\n",
      "   macro avg       0.14      0.21      0.15      4500\n",
      "weighted avg       0.14      0.20      0.14      4500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20466666666666666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GATConv\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_code_snippets(code_snippets):\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from gensim.models import Word2Vec\n",
    "\n",
    "    tokenized = [word_tokenize(code) for code in code_snippets]\n",
    "    model = Word2Vec(tokenized, vector_size=128, window=5, min_count=1, workers=4)\n",
    "\n",
    "    embeddings = [\n",
    "        np.mean([model.wv[token] for token in tokens if token in model.wv], axis=0)\n",
    "        for tokens in tokenized\n",
    "    ]\n",
    "\n",
    "    return np.array(embeddings)\n",
    "\n",
    "def generate_pdg(feature_matrix):\n",
    "    num_nodes = feature_matrix.shape[0]\n",
    "    edge_index = torch.combinations(torch.arange(num_nodes), r=2).T\n",
    "    edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "    return edge_index\n",
    "\n",
    "def prepare_graph_data(features, labels):\n",
    "    data_list = []\n",
    "    for i in range(len(features)):\n",
    "        x = torch.tensor(features[i], dtype=torch.float).unsqueeze(0)\n",
    "        edge_index = generate_pdg(x)\n",
    "        y = torch.tensor([labels[i]], dtype=torch.long)\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "class VulnerabilityGCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(VulnerabilityGCN, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=4, concat=True)\n",
    "        self.conv2 = GATConv(hidden_dim * 4, hidden_dim, heads=1, concat=False)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def load_data(train_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    X_train = train_df['functionSource']\n",
    "    y_train = train_df['numeric']\n",
    "\n",
    "    X_test = test_df['functionSource']\n",
    "    y_test = test_df['numeric']\n",
    "\n",
    "    train_embeddings = preprocess_code_snippets(X_train)\n",
    "    test_embeddings = preprocess_code_snippets(X_test)\n",
    "\n",
    "    train_data = prepare_graph_data(train_embeddings, y_train)\n",
    "    test_data = prepare_graph_data(test_embeddings, y_test)\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == data.y).sum().item()\n",
    "            total += data.num_graphs\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "            y_pred.extend(pred.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "train_path ='/Users/akter/Documents/MSR update/ICSME version/Train-Test daatset/Splited dataset/train_label_dataset.csv'\n",
    "test_path= '/Users/akter/Documents/MSR update/ICSME version/Train-Test daatset/Splited dataset/test_label_dataset.csv'\n",
    "\n",
    "train_data, test_data = load_data(train_path, test_path)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "model = VulnerabilityGCN(input_dim=128, hidden_dim=64, output_dim=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(1, 21):\n",
    "    loss = train(model, train_loader, optimizer, criterion)\n",
    "    print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "print(\"Performance on Test Set:\")\n",
    "evaluate(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90959aa6-9fbc-400e-8eb2-e9e4921d7977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       934\n",
      "           1       0.24      0.35      0.29       860\n",
      "           2       0.00      0.00      0.00       918\n",
      "           3       0.29      0.12      0.17       909\n",
      "           4       0.18      0.58      0.27       879\n",
      "\n",
      "    accuracy                           0.20      4500\n",
      "   macro avg       0.14      0.21      0.15      4500\n",
      "weighted avg       0.14      0.20      0.14      4500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0 260   0  84 590]\n",
      " [  0 303   0  51 506]\n",
      " [  0 171   0  81 666]\n",
      " [  0 206   0 110 593]\n",
      " [  0 312   0  59 508]]\n",
      "\n",
      "Accuracy: 0.20466666666666666\n",
      "\n",
      "Precision (Macro): 0.1410326641885732\n",
      "Recall (Macro): 0.21025342958138976\n",
      "F1 Score (Macro): 0.14569196685212654\n",
      "\n",
      "Precision (Weighted): 0.1386248321930458\n",
      "Recall (Weighted): 0.20466666666666666\n",
      "F1 Score (Weighted): 0.14221443409959064\n",
      "\n",
      "Matthews Correlation Coefficient: 0.015552240694647222\n",
      "\n",
      "Cohen's Kappa Score: 0.012340788206691045\n",
      "\n",
      "ROC AUC Score (Macro): 0.5133132554525345\n",
      "\n",
      "Mean Squared Error (MSE): 4.980888888888889\n",
      "Mean Absolute Error (MAE): 1.7946666666666666\n",
      "\n",
      "Metrics Summary:\n",
      "Accuracy: 0.20466666666666666\n",
      "Precision (Macro): 0.1410326641885732\n",
      "Recall (Macro): 0.21025342958138976\n",
      "F1 Score (Macro): 0.14569196685212654\n",
      "Precision (Weighted): 0.1386248321930458\n",
      "Recall (Weighted): 0.20466666666666666\n",
      "F1 Score (Weighted): 0.14221443409959064\n",
      "Matthews Correlation Coefficient (MCC): 0.015552240694647222\n",
      "Cohen's Kappa: 0.012340788206691045\n",
      "Mean Squared Error (MSE): 4.980888888888889\n",
      "Mean Absolute Error (MAE): 1.7946666666666666\n",
      "ROC AUC Score (Macro): 0.5133132554525345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    cohen_kappa_score,\n",
    "    roc_auc_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "\n",
    "Y_pred = []\n",
    "Y_true = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        predictions = output.argmax(dim=1).cpu().numpy()  \n",
    "        Y_pred.extend(predictions)\n",
    "        Y_true.extend(data.y.cpu().numpy())  \n",
    "        \n",
    "Y_pred = np.array(Y_pred)\n",
    "Y_true = np.array(Y_true)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_true, Y_pred, zero_division=0))\n",
    "\n",
    "conf_matrix = confusion_matrix(Y_true, Y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(Y_true, Y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "\n",
    "precision_macro = precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0)\n",
    "recall_macro = recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0)\n",
    "f1_macro = f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "precision_weighted = precision_score(Y_true, Y_pred, average=\"weighted\", zero_division=0)\n",
    "recall_weighted = recall_score(Y_true, Y_pred, average=\"weighted\", zero_division=0)\n",
    "f1_weighted = f1_score(Y_true, Y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(f\"\\nPrecision (Macro): {precision_macro}\")\n",
    "print(f\"Recall (Macro): {recall_macro}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro}\")\n",
    "\n",
    "print(f\"\\nPrecision (Weighted): {precision_weighted}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted}\")\n",
    "\n",
    "mcc = matthews_corrcoef(Y_true, Y_pred)\n",
    "print(f\"\\nMatthews Correlation Coefficient: {mcc}\")\n",
    "\n",
    "kappa = cohen_kappa_score(Y_true, Y_pred)\n",
    "print(f\"\\nCohen's Kappa Score: {kappa}\")\n",
    "\n",
    "try:\n",
    "    roc_auc = roc_auc_score(pd.get_dummies(Y_true), pd.get_dummies(Y_pred), multi_class=\"ovr\", average=\"macro\")\n",
    "    print(f\"\\nROC AUC Score (Macro): {roc_auc}\")\n",
    "except ValueError:\n",
    "    print(\"\\nROC AUC Score could not be computed due to label imbalance or insufficient classes.\")\n",
    "\n",
    "mse = mean_squared_error(Y_true, Y_pred)\n",
    "mae = mean_absolute_error(Y_true, Y_pred)\n",
    "\n",
    "print(f\"\\nMean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "\n",
    "metrics_summary = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision (Macro)\": precision_macro,\n",
    "    \"Recall (Macro)\": recall_macro,\n",
    "    \"F1 Score (Macro)\": f1_macro,\n",
    "    \"Precision (Weighted)\": precision_weighted,\n",
    "    \"Recall (Weighted)\": recall_weighted,\n",
    "    \"F1 Score (Weighted)\": f1_weighted,\n",
    "    \"Matthews Correlation Coefficient (MCC)\": mcc,\n",
    "    \"Cohen's Kappa\": kappa,\n",
    "    \"Mean Squared Error (MSE)\": mse,\n",
    "    \"Mean Absolute Error (MAE)\": mae,\n",
    "}\n",
    "\n",
    "if \"roc_auc\" in locals():\n",
    "    metrics_summary[\"ROC AUC Score (Macro)\"] = roc_auc\n",
    "\n",
    "print(\"\\nMetrics Summary:\")\n",
    "for metric, value in metrics_summary.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09a4c4fc-b01b-49dc-8b71-df2649bf29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_df = pd.DataFrame([metrics_summary])\n",
    "metrics_df.to_csv(\"/Users/akter/Documents/MSR update/ICSME version//All Embeddings dataset/SOTA extracted dataset/SOTA_performances/IVDet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760db506-5e1c-4c19-ab11-3d6fc087c615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
