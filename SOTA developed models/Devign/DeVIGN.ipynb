{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f53b6717-477d-4565-8e83-5373adb72456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate, Layer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "# train = pd.read_csv('/Users/akter/Documents/MSR update//ICSME version/Test cases/Deviing quemu/Devign_quemu_train.csv')\n",
    "# test = pd.read_csv('/Users/akter/Documents/MSR update/ICSME version/Train-Test daatset/Splited dataset/test_label_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b628ead-4024-4c6b-b343-ed5e26719c5e",
   "metadata": {},
   "source": [
    "### on devign data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "434faccb-517a-402f-b2e7-e2194906de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6909\n",
      "Epoch 2/20, Loss: 0.6893\n",
      "Epoch 3/20, Loss: 0.6892\n",
      "Epoch 4/20, Loss: 0.6893\n",
      "Epoch 5/20, Loss: 0.6892\n",
      "Epoch 6/20, Loss: 0.6887\n",
      "Epoch 7/20, Loss: 0.6892\n",
      "Epoch 8/20, Loss: 0.6893\n",
      "Epoch 9/20, Loss: 0.6891\n",
      "Epoch 10/20, Loss: 0.6895\n",
      "Epoch 11/20, Loss: 0.6894\n",
      "Epoch 12/20, Loss: 0.6887\n",
      "Epoch 13/20, Loss: 0.6893\n",
      "Epoch 14/20, Loss: 0.6892\n",
      "Epoch 15/20, Loss: 0.6887\n",
      "Epoch 16/20, Loss: 0.6890\n",
      "Epoch 17/20, Loss: 0.6895\n",
      "Epoch 18/20, Loss: 0.6888\n",
      "Epoch 19/20, Loss: 0.6893\n",
      "Epoch 20/20, Loss: 0.6889\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, cohen_kappa_score, mean_squared_error, mean_absolute_error\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "class GGGNN(nn.Module):\n",
    "    def __init__(self, feature_dim_size, hidden_size, num_GNN_layers, num_classes, dropout):\n",
    "        super(GGGNN, self).__init__()\n",
    "        self.fc = nn.Linear(feature_dim_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_GNN_layers)])\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, adj, adj_mask):\n",
    "        h = self.fc(x)\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        h = self.dropout(h)\n",
    "        return self.classifier(h.mean(dim=1))\n",
    "\n",
    "class DevignModel(nn.Module):\n",
    "    def __init__(self, config, args):\n",
    "        super(DevignModel, self).__init__()\n",
    "        self.args = args\n",
    "        self.w_embeddings = torch.randn(args.vocab_size, args.feature_dim_size)\n",
    "        self.gnn = GGGNN(feature_dim_size=args.feature_dim_size, hidden_size=args.hidden_size, num_GNN_layers=args.num_GNN_layers, num_classes=args.hidden_size, dropout=config.hidden_dropout_prob)\n",
    "        self.conv1 = nn.Conv1d(args.hidden_size, args.hidden_size, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv1d(args.hidden_size, args.hidden_size, kernel_size=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(args.hidden_size, args.num_classes)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        adj, x_feature = build_graph(input_ids.cpu().numpy(), self.w_embeddings.numpy())\n",
    "        adj, adj_mask = preprocess_adj(adj)\n",
    "        adj_feature = preprocess_features(x_feature)\n",
    "        adj = torch.from_numpy(adj).float().to(input_ids.device)\n",
    "        adj_mask = torch.from_numpy(adj_mask).float().to(input_ids.device)\n",
    "        adj_feature = torch.from_numpy(adj_feature).float().to(input_ids.device)\n",
    "        outputs = self.gnn(adj_feature, adj, adj_mask)\n",
    "        outputs = outputs.unsqueeze(2)\n",
    "        if outputs.size(2) >= 3:\n",
    "            outputs = self.pool1(torch.relu(self.conv1(outputs))).squeeze(2)\n",
    "            if outputs.size(2) >= 2:\n",
    "                outputs = self.pool2(torch.relu(self.conv2(outputs))).squeeze(2)\n",
    "        else:\n",
    "            outputs = outputs.squeeze(2)\n",
    "        logits = self.fc(outputs)\n",
    "        prob = torch.softmax(logits, dim=1)\n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "            return loss, prob\n",
    "        return prob\n",
    "\n",
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_len, word2vec_model):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.word2vec = word2vec_model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        code = self.data.iloc[idx]['input']\n",
    "        label = int(self.data.iloc[idx]['output'])\n",
    "        tokens = self.tokenizer(code, max_length=self.max_len, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "        input_ids = tokens['input_ids'].squeeze(0)\n",
    "        return input_ids, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def build_graph(input_ids, w_embeddings):\n",
    "    batch_size, seq_len = input_ids.shape\n",
    "    vocab_size, feature_dim_size = w_embeddings.shape\n",
    "    x_feature = w_embeddings[input_ids]\n",
    "    num_nodes = seq_len\n",
    "    adj = np.ones((batch_size, num_nodes, num_nodes))\n",
    "    return adj, x_feature\n",
    "\n",
    "def preprocess_adj(adj):\n",
    "    adj_mask = np.ones_like(adj)\n",
    "    return adj, adj_mask\n",
    "\n",
    "def preprocess_features(features):\n",
    "    return features\n",
    "\n",
    "class Config:\n",
    "    hidden_dropout_prob = 0.1\n",
    "\n",
    "class Args:\n",
    "    vocab_size = 10000\n",
    "    feature_dim_size = 128\n",
    "    hidden_size = 200\n",
    "    num_GNN_layers = 6\n",
    "    num_classes = 2\n",
    "    max_len = 128\n",
    "    batch_size = 128\n",
    "    learning_rate = 1e-4\n",
    "    epochs = 20\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = Config()\n",
    "    args = Args()\n",
    "    word2vec_model = Word2Vec(vector_size=args.feature_dim_size, min_count=1)\n",
    "    tokenizer = lambda x, max_length, truncation, padding, return_tensors: {\n",
    "        'input_ids': torch.randint(0, args.vocab_size, (1, max_length))\n",
    "    }\n",
    "    train_dataset = CodeDataset(csv_file=\"/Users/user01/fahim/icsme/Devign/devign_vultest.csv\", tokenizer=tokenizer, max_len=args.max_len, word2vec_model=word2vec_model)\n",
    "    test_dataset = CodeDataset(csv_file=\"/Users/user01/fahim/icsme/Devign/devign_vultest.csv\", tokenizer=tokenizer, max_len=args.max_len, word2vec_model=word2vec_model)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "    model = DevignModel(config, args).float()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    for epoch in range(args.epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            input_ids, labels = batch\n",
    "            input_ids = input_ids.to(torch.long).to(model.w_embeddings.device)\n",
    "            labels = labels.to(torch.long).to(model.w_embeddings.device)\n",
    "            optimizer.zero_grad()\n",
    "            loss, _ = model(input_ids, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{args.epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90959aa6-9fbc-400e-8eb2-e9e4921d7977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71      1021\n",
      "           1       0.00      0.00      0.00       852\n",
      "\n",
      "    accuracy                           0.55      1873\n",
      "   macro avg       0.27      0.50      0.35      1873\n",
      "weighted avg       0.30      0.55      0.38      1873\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1021    0]\n",
      " [ 852    0]]\n",
      "\n",
      "Accuracy: 0.5451147891083823\n",
      "\n",
      "Precision (Macro): 0.27255739455419115\n",
      "Recall (Macro): 0.5\n",
      "F1 Score (Macro): 0.35279889426399447\n",
      "\n",
      "Precision (Weighted): 0.2971501333046761\n",
      "Recall (Weighted): 0.5451147891083823\n",
      "F1 Score (Weighted): 0.3846317896887756\n",
      "\n",
      "Matthews Correlation Coefficient: 0.0\n",
      "\n",
      "Cohen's Kappa Score: 0.0\n",
      "\n",
      "ROC AUC Score (Macro): 0.5\n",
      "\n",
      "Mean Squared Error (MSE): 0.4548852108916177\n",
      "Mean Absolute Error (MAE): 0.4548852108916177\n",
      "\n",
      "Metrics Summary:\n",
      "Accuracy: 0.5451147891083823\n",
      "Precision (Macro): 0.27255739455419115\n",
      "Recall (Macro): 0.5\n",
      "F1 Score (Macro): 0.35279889426399447\n",
      "Precision (Weighted): 0.2971501333046761\n",
      "Recall (Weighted): 0.5451147891083823\n",
      "F1 Score (Weighted): 0.3846317896887756\n",
      "Matthews Correlation Coefficient (MCC): 0.0\n",
      "Cohen's Kappa: 0.0\n",
      "Mean Squared Error (MSE): 0.4548852108916177\n",
      "Mean Absolute Error (MAE): 0.4548852108916177\n",
      "ROC AUC Score (Macro): 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    cohen_kappa_score,\n",
    "    roc_auc_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "\n",
    "Y_pred = []\n",
    "Y_true = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        input_ids, labels = data\n",
    "        input_ids = input_ids.to(torch.long).to(model.w_embeddings.device)\n",
    "        labels = labels.to(torch.long).to(model.w_embeddings.device)\n",
    "\n",
    "        output = model(input_ids)\n",
    "        predictions = output.argmax(dim=1).cpu().numpy()  \n",
    "        Y_pred.extend(predictions)\n",
    "        Y_true.extend(labels.cpu().numpy())  \n",
    "\n",
    "Y_pred = np.array(Y_pred)\n",
    "Y_true = np.array(Y_true)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_true, Y_pred, zero_division=0))\n",
    "\n",
    "conf_matrix = confusion_matrix(Y_true, Y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "accuracy = accuracy_score(Y_true, Y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "\n",
    "precision_macro = precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0)\n",
    "recall_macro = recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0)\n",
    "f1_macro = f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "precision_weighted = precision_score(Y_true, Y_pred, average=\"weighted\", zero_division=0)\n",
    "recall_weighted = recall_score(Y_true, Y_pred, average=\"weighted\", zero_division=0)\n",
    "f1_weighted = f1_score(Y_true, Y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(f\"\\nPrecision (Macro): {precision_macro}\")\n",
    "print(f\"Recall (Macro): {recall_macro}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro}\")\n",
    "print(f\"\\nPrecision (Weighted): {precision_weighted}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted}\")\n",
    "\n",
    "mcc = matthews_corrcoef(Y_true, Y_pred)\n",
    "print(f\"\\nMatthews Correlation Coefficient: {mcc}\")\n",
    "\n",
    "kappa = cohen_kappa_score(Y_true, Y_pred)\n",
    "print(f\"\\nCohen's Kappa Score: {kappa}\")\n",
    "\n",
    "try:\n",
    "    roc_auc = roc_auc_score(pd.get_dummies(Y_true), pd.get_dummies(Y_pred), multi_class=\"ovr\", average=\"macro\")\n",
    "    print(f\"\\nROC AUC Score (Macro): {roc_auc}\")\n",
    "except ValueError:\n",
    "    print(\"\\nROC AUC Score could not be computed due to label imbalance or insufficient classes.\")\n",
    "\n",
    "mse = mean_squared_error(Y_true, Y_pred)\n",
    "mae = mean_absolute_error(Y_true, Y_pred)\n",
    "\n",
    "print(f\"\\nMean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "metrics_summary = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision (Macro)\": precision_macro,\n",
    "    \"Recall (Macro)\": recall_macro,\n",
    "    \"F1 Score (Macro)\": f1_macro,\n",
    "    \"Precision (Weighted)\": precision_weighted,\n",
    "    \"Recall (Weighted)\": recall_weighted,\n",
    "    \"F1 Score (Weighted)\": f1_weighted,\n",
    "    \"Matthews Correlation Coefficient (MCC)\": mcc,\n",
    "    \"Cohen's Kappa\": kappa,\n",
    "    \"Mean Squared Error (MSE)\": mse,\n",
    "    \"Mean Absolute Error (MAE)\": mae,\n",
    "}\n",
    "\n",
    "if \"roc_auc\" in locals():\n",
    "    metrics_summary[\"ROC AUC Score (Macro)\"] = roc_auc\n",
    "\n",
    "print(\"\\nMetrics Summary:\")\n",
    "for metric, value in metrics_summary.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ba35c-8bc8-4a84-ac04-f2c341d909f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b80a3-7a56-4ff6-b11b-7ba08288a840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a18042e-c322-4aff-8b2f-f3fcab2a7d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cdc831a-33ab-4525-a1d0-37931215dad0",
   "metadata": {},
   "source": [
    "### on draper data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b287d257-b834-4519-afa8-5c20242d0777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.6098\n",
      "Epoch 2/20, Loss: 1.6096\n",
      "Epoch 3/20, Loss: 1.6096\n",
      "Epoch 4/20, Loss: 1.6096\n",
      "Epoch 5/20, Loss: 1.6097\n",
      "Epoch 6/20, Loss: 1.6096\n",
      "Epoch 7/20, Loss: 1.6096\n",
      "Epoch 8/20, Loss: 1.6096\n",
      "Epoch 9/20, Loss: 1.6096\n",
      "Epoch 10/20, Loss: 1.6096\n",
      "Epoch 11/20, Loss: 1.6096\n",
      "Epoch 12/20, Loss: 1.6096\n",
      "Epoch 13/20, Loss: 1.6096\n",
      "Epoch 14/20, Loss: 1.6095\n",
      "Epoch 15/20, Loss: 1.6096\n",
      "Epoch 16/20, Loss: 1.6096\n",
      "Epoch 17/20, Loss: 1.6096\n",
      "Epoch 18/20, Loss: 1.6095\n",
      "Epoch 19/20, Loss: 1.6096\n",
      "Epoch 20/20, Loss: 1.6095\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, cohen_kappa_score, mean_squared_error, mean_absolute_error\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "class GGGNN(nn.Module):\n",
    "    def __init__(self, feature_dim_size, hidden_size, num_GNN_layers, num_classes, dropout):\n",
    "        super(GGGNN, self).__init__()\n",
    "        self.fc = nn.Linear(feature_dim_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_GNN_layers)])\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, adj, adj_mask):\n",
    "        h = self.fc(x)\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        h = self.dropout(h)\n",
    "        return self.classifier(h.mean(dim=1))\n",
    "\n",
    "class DevignModel(nn.Module):\n",
    "    def __init__(self, config, args):\n",
    "        super(DevignModel, self).__init__()\n",
    "        self.args = args\n",
    "        self.w_embeddings = torch.randn(args.vocab_size, args.feature_dim_size)\n",
    "        self.gnn = GGGNN(feature_dim_size=args.feature_dim_size, hidden_size=args.hidden_size, num_GNN_layers=args.num_GNN_layers, num_classes=args.hidden_size, dropout=config.hidden_dropout_prob)\n",
    "        self.conv1 = nn.Conv1d(args.hidden_size, args.hidden_size, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv1d(args.hidden_size, args.hidden_size, kernel_size=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(args.hidden_size, args.num_classes)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        adj, x_feature = build_graph(input_ids.cpu().numpy(), self.w_embeddings.numpy())\n",
    "        adj, adj_mask = preprocess_adj(adj)\n",
    "        adj_feature = preprocess_features(x_feature)\n",
    "        adj = torch.from_numpy(adj).float().to(input_ids.device)\n",
    "        adj_mask = torch.from_numpy(adj_mask).float().to(input_ids.device)\n",
    "        adj_feature = torch.from_numpy(adj_feature).float().to(input_ids.device)\n",
    "        outputs = self.gnn(adj_feature, adj, adj_mask)\n",
    "        outputs = outputs.unsqueeze(2)\n",
    "        if outputs.size(2) >= 3:\n",
    "            outputs = self.pool1(torch.relu(self.conv1(outputs))).squeeze(2)\n",
    "            if outputs.size(2) >= 2:\n",
    "                outputs = self.pool2(torch.relu(self.conv2(outputs))).squeeze(2)\n",
    "        else:\n",
    "            outputs = outputs.squeeze(2)\n",
    "        logits = self.fc(outputs)\n",
    "        prob = torch.softmax(logits, dim=1)\n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "            return loss, prob\n",
    "        return prob\n",
    "\n",
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_len, word2vec_model):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.word2vec = word2vec_model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        code = self.data.iloc[idx]['functionSource']\n",
    "        label = int(self.data.iloc[idx]['numeric'])\n",
    "        tokens = self.tokenizer(code, max_length=self.max_len, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "        input_ids = tokens['input_ids'].squeeze(0)\n",
    "        return input_ids, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def build_graph(input_ids, w_embeddings):\n",
    "    batch_size, seq_len = input_ids.shape\n",
    "    vocab_size, feature_dim_size = w_embeddings.shape\n",
    "    x_feature = w_embeddings[input_ids]\n",
    "    num_nodes = seq_len\n",
    "    adj = np.ones((batch_size, num_nodes, num_nodes))\n",
    "    return adj, x_feature\n",
    "\n",
    "def preprocess_adj(adj):\n",
    "    adj_mask = np.ones_like(adj)\n",
    "    return adj, adj_mask\n",
    "\n",
    "def preprocess_features(features):\n",
    "    return features\n",
    "\n",
    "class Config:\n",
    "    hidden_dropout_prob = 0.1\n",
    "\n",
    "class Args:\n",
    "    vocab_size = 10000\n",
    "    feature_dim_size = 128\n",
    "    hidden_size = 200\n",
    "    num_GNN_layers = 6\n",
    "    num_classes = 5\n",
    "    max_len = 128\n",
    "    batch_size = 128\n",
    "    learning_rate = 1e-4\n",
    "    epochs = 20\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = Config()\n",
    "    args = Args()\n",
    "    word2vec_model = Word2Vec(vector_size=args.feature_dim_size, min_count=1)\n",
    "    tokenizer = lambda x, max_length, truncation, padding, return_tensors: {\n",
    "        'input_ids': torch.randint(0, args.vocab_size, (1, max_length))\n",
    "    }\n",
    "    train_dataset = CodeDataset(csv_file=\"/Users/user01/fahim/icsme/train_label_dataset.csv\", tokenizer=tokenizer, max_len=args.max_len, word2vec_model=word2vec_model)\n",
    "    test_dataset = CodeDataset(csv_file=\"/Users/user01/fahim/icsme/test_label_dataset.csv\", tokenizer=tokenizer, max_len=args.max_len, word2vec_model=word2vec_model)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "    model = DevignModel(config, args).float()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    for epoch in range(args.epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            input_ids, labels = batch\n",
    "            input_ids = input_ids.to(torch.long).to(model.w_embeddings.device)\n",
    "            labels = labels.to(torch.long).to(model.w_embeddings.device)\n",
    "            optimizer.zero_grad()\n",
    "            loss, _ = model(input_ids, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{args.epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f83dee30-57cb-4bea-b0ba-cd8c224bf7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       934\n",
      "           1       0.00      0.00      0.00       860\n",
      "           2       0.00      0.00      0.00       918\n",
      "           3       0.00      0.00      0.00       909\n",
      "           4       0.20      1.00      0.33       879\n",
      "\n",
      "    accuracy                           0.20      4500\n",
      "   macro avg       0.04      0.20      0.07      4500\n",
      "weighted avg       0.04      0.20      0.06      4500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   0 934]\n",
      " [  0   0   0   0 860]\n",
      " [  0   0   0   0 918]\n",
      " [  0   0   0   0 909]\n",
      " [  0   0   0   0 879]]\n",
      "\n",
      "Accuracy: 0.19533333333333333\n",
      "\n",
      "Precision (Macro): 0.039066666666666666\n",
      "Recall (Macro): 0.2\n",
      "F1 Score (Macro): 0.06536530953708868\n",
      "\n",
      "Precision (Weighted): 0.03815511111111111\n",
      "Recall (Weighted): 0.19533333333333333\n",
      "F1 Score (Weighted): 0.06384011898122327\n",
      "\n",
      "Matthews Correlation Coefficient: 0.0\n",
      "\n",
      "Cohen's Kappa Score: 0.0\n",
      "\n",
      "ROC AUC Score (Macro): 0.5021250261672968\n",
      "\n",
      "Mean Squared Error (MSE): 6.058888888888889\n",
      "Mean Absolute Error (MAE): 2.0135555555555555\n",
      "\n",
      "Metrics Summary:\n",
      "Accuracy: 0.19533333333333333\n",
      "Precision (Macro): 0.039066666666666666\n",
      "Recall (Macro): 0.2\n",
      "F1 Score (Macro): 0.06536530953708868\n",
      "Precision (Weighted): 0.03815511111111111\n",
      "Recall (Weighted): 0.19533333333333333\n",
      "F1 Score (Weighted): 0.06384011898122327\n",
      "Matthews Correlation Coefficient (MCC): 0.0\n",
      "Cohen's Kappa: 0.0\n",
      "Mean Squared Error (MSE): 6.058888888888889\n",
      "Mean Absolute Error (MAE): 2.0135555555555555\n",
      "ROC AUC Score (Macro): 0.5021250261672968\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    cohen_kappa_score,\n",
    "    roc_auc_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "\n",
    "# Storing predictions and ground truths\n",
    "Y_pred = []\n",
    "Y_true = []\n",
    "Y_prob = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        input_ids, labels = data\n",
    "        input_ids = input_ids.to(torch.long).to(model.w_embeddings.device)\n",
    "        labels = labels.to(torch.long).to(model.w_embeddings.device)\n",
    "\n",
    "        output = model(input_ids)  # Raw logits\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)  # Convert logits to probabilities\n",
    "        predictions = output.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        Y_pred.extend(predictions)\n",
    "        Y_true.extend(labels.cpu().numpy())\n",
    "        Y_prob.extend(probabilities.cpu().numpy())  # Store probability scores\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "Y_pred = np.array(Y_pred)\n",
    "Y_true = np.array(Y_true)\n",
    "Y_prob = np.array(Y_prob)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_true, Y_pred, zero_division=0))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_true, Y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Extracting TP, TN, FP, FN for binary classification\n",
    "if conf_matrix.shape == (2, 2):  \n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    \n",
    "    # Sensitivity (Recall) - True Positive Rate (TPR)\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    \n",
    "    # Specificity - True Negative Rate (TNR)\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    \n",
    "    # False Positive Rate (FPR)\n",
    "    fpr = FP / (FP + TN) if (FP + TN) != 0 else 0\n",
    "\n",
    "    # False Negative Rate (FNR)\n",
    "    fnr = FN / (FN + TP) if (FN + TP) != 0 else 0\n",
    "\n",
    "    print(f\"\\nTrue Positives (TP): {TP}\")\n",
    "    print(f\"True Negatives (TN): {TN}\")\n",
    "    print(f\"False Positives (FP): {FP}\")\n",
    "    print(f\"False Negatives (FN): {FN}\")\n",
    "    print(f\"\\nSensitivity (Recall / TPR): {sensitivity}\")\n",
    "    print(f\"Specificity (TNR): {specificity}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr}\")\n",
    "    print(f\"False Negative Rate (FNR): {fnr}\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(Y_true, Y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "\n",
    "# Precision, Recall, F1-score (Macro & Weighted)\n",
    "precision_macro = precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0)\n",
    "recall_macro = recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0)\n",
    "f1_macro = f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "precision_weighted = precision_score(Y_true, Y_pred, average=\"weighted\", zero_division=0)\n",
    "recall_weighted = recall_score(Y_true, Y_pred, average=\"weighted\", zero_division=0)\n",
    "f1_weighted = f1_score(Y_true, Y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(f\"\\nPrecision (Macro): {precision_macro}\")\n",
    "print(f\"Recall (Macro): {recall_macro}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro}\")\n",
    "print(f\"\\nPrecision (Weighted): {precision_weighted}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted}\")\n",
    "\n",
    "# MCC & Cohen's Kappa\n",
    "mcc = matthews_corrcoef(Y_true, Y_pred)\n",
    "print(f\"\\nMatthews Correlation Coefficient: {mcc}\")\n",
    "\n",
    "kappa = cohen_kappa_score(Y_true, Y_pred)\n",
    "print(f\"\\nCohen's Kappa Score: {kappa}\")\n",
    "\n",
    "# ROC AUC Score (Multiclass)\n",
    "try:\n",
    "    roc_auc = roc_auc_score(pd.get_dummies(Y_true), Y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "    print(f\"\\nROC AUC Score (Macro): {roc_auc}\")\n",
    "except ValueError as e:\n",
    "    print(f\"\\nROC AUC Score could not be computed: {e}\")\n",
    "\n",
    "# Mean Squared Error & Mean Absolute Error\n",
    "mse = mean_squared_error(Y_true, Y_pred)\n",
    "mae = mean_absolute_error(Y_true, Y_pred)\n",
    "\n",
    "print(f\"\\nMean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Summary of all metrics\n",
    "metrics_summary = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision (Macro)\": precision_macro,\n",
    "    \"Recall (Macro)\": recall_macro,\n",
    "    \"F1 Score (Macro)\": f1_macro,\n",
    "    \"Precision (Weighted)\": precision_weighted,\n",
    "    \"Recall (Weighted)\": recall_weighted,\n",
    "    \"F1 Score (Weighted)\": f1_weighted,\n",
    "    \"Matthews Correlation Coefficient (MCC)\": mcc,\n",
    "    \"Cohen's Kappa\": kappa,\n",
    "    \"Mean Squared Error (MSE)\": mse,\n",
    "    \"Mean Absolute Error (MAE)\": mae,\n",
    "}\n",
    "\n",
    "if \"roc_auc\" in locals():\n",
    "    metrics_summary[\"ROC AUC Score (Macro)\"] = roc_auc\n",
    "\n",
    "if conf_matrix.shape == (2, 2):  # Include these metrics only for binary classification\n",
    "    metrics_summary.update({\n",
    "        \"True Positives (TP)\": TP,\n",
    "        \"True Negatives (TN)\": TN,\n",
    "        \"False Positives (FP)\": FP,\n",
    "        \"False Negatives (FN)\": FN,\n",
    "        \"Sensitivity (Recall / TPR)\": sensitivity,\n",
    "        \"Specificity (TNR)\": specificity,\n",
    "        \"False Positive Rate (FPR)\": fpr,\n",
    "        \"False Negative Rate (FNR)\": fnr,\n",
    "    })\n",
    "\n",
    "print(\"\\nMetrics Summary:\")\n",
    "for metric, value in metrics_summary.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90f0112b-b580-4fd9-bd69-b7d442b06cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall True Positives (TP): 879\n",
      "Overall False Positives (FP): 3621\n",
      "Overall False Negatives (FN): 3621\n",
      "Overall True Negatives (TN): 10863\n",
      "\n",
      "Overall Sensitivity (Recall): 0.10965568862275449\n",
      "Overall Specificity: 0.75\n",
      "\n",
      "Updated Metrics Summary:\n",
      "Accuracy: 0.19533333333333333\n",
      "Precision (Macro): 0.039066666666666666\n",
      "Recall (Macro): 0.2\n",
      "F1 Score (Macro): 0.06536530953708868\n",
      "Precision (Weighted): 0.03815511111111111\n",
      "Recall (Weighted): 0.19533333333333333\n",
      "F1 Score (Weighted): 0.06384011898122327\n",
      "Matthews Correlation Coefficient (MCC): 0.0\n",
      "Cohen's Kappa: 0.0\n",
      "Mean Squared Error (MSE): 6.058888888888889\n",
      "Mean Absolute Error (MAE): 2.0135555555555555\n",
      "ROC AUC Score (Macro): 0.5021250261672968\n",
      "True Positives (TP): 879\n",
      "False Positives (FP): 3621\n",
      "False Negatives (FN): 3621\n",
      "True Negatives (TN): 10863\n",
      "Sensitivity (Recall): 0.10965568862275449\n",
      "Specificity: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_true, Y_pred)\n",
    "\n",
    "# Aggregate TP, FP, FN, TN across all classes\n",
    "TP = np.diag(conf_matrix).sum()  # Sum of diagonal elements (True Positives)\n",
    "FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  # Column-wise sum minus TP\n",
    "FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)  # Row-wise sum minus TP\n",
    "TN = conf_matrix.sum() - (FP + FN + TP)  # Total elements minus others\n",
    "\n",
    "# Compute overall sensitivity (Recall) & specificity\n",
    "SP = TN.sum() / (TN.sum() + FP.sum())  # Specificity\n",
    "SN = TP / (TP + FN).sum()  # Sensitivity (Recall)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nOverall True Positives (TP): {TP}\")\n",
    "print(f\"Overall False Positives (FP): {FP.sum()}\")\n",
    "print(f\"Overall False Negatives (FN): {FN.sum()}\")\n",
    "print(f\"Overall True Negatives (TN): {TN.sum()}\")\n",
    "print(f\"\\nOverall Sensitivity (Recall): {SN}\")\n",
    "print(f\"Overall Specificity: {SP}\")\n",
    "\n",
    "# Add these metrics to the summary\n",
    "metrics_summary.update({\n",
    "    \"True Positives (TP)\": TP,\n",
    "    \"False Positives (FP)\": FP.sum(),\n",
    "    \"False Negatives (FN)\": FN.sum(),\n",
    "    \"True Negatives (TN)\": TN.sum(),\n",
    "    \"Sensitivity (Recall)\": SN,\n",
    "    \"Specificity\": SP,\n",
    "})\n",
    "\n",
    "print(\"\\nUpdated Metrics Summary:\")\n",
    "for metric, value in metrics_summary.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305a142-1407-46e8-9e4b-fa02d0546a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
